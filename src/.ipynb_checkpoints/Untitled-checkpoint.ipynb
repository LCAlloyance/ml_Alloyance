{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285f1e0-0667-4ad2-aa42-0a6f7ec516c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- Load your real dataset ---\n",
    "file_path = os.path.join(\"..\", \"data\", \"lca_dataset.csv\")\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {file_path}\")\n",
    "\n",
    "df_training = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Separate categorical and numeric columns\n",
    "categorical_cols = df_training.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_cols = df_training.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# 2. Encode all categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_training[col] = le.fit_transform(df_training[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 3. Fit Iterative Imputer\n",
    "imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "    max_iter=10,\n",
    "    random_state=0\n",
    ")\n",
    "imputer.fit(df_training)\n",
    "\n",
    "def autofill_lca_data(json_input):\n",
    "    \"\"\"\n",
    "    Takes a JSON input from a user, applies hybrid autofill logic,\n",
    "    and returns a fully imputed pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # 1. Load the JSON input into a DataFrame\n",
    "    user_data = json.loads(json_input)\n",
    "    df_user = pd.DataFrame([user_data])\n",
    "\n",
    "    # --- Rule-based default example (optional, can add more rules) ---\n",
    "    if \"Process Stage\" in df_user.columns and df_user[\"Process Stage\"].iloc[0] == \"End-of-Life\":\n",
    "        if \"End-of-Life Treatment\" not in df_user or pd.isna(df_user[\"End-of-Life Treatment\"]).any():\n",
    "            df_user[\"End-of-Life Treatment\"] = \"Recycling\"\n",
    "\n",
    "    # 2. Align columns with training set\n",
    "    df_user = df_user.reindex(columns=df_training.columns, fill_value=np.nan)\n",
    "\n",
    "    # 3. Encode categorical columns\n",
    "    for col in categorical_cols:\n",
    "        if col in df_user.columns:\n",
    "            df_user[col] = df_user[col].apply(\n",
    "                lambda x: label_encoders[col].transform([x])[0]\n",
    "                if pd.notna(x) and x in label_encoders[col].classes_\n",
    "                else np.nan  # use NaN for unknown categories (lets imputer fill)\n",
    "            )\n",
    "\n",
    "    # 4. Apply imputation\n",
    "    imputed_array = imputer.transform(df_user)\n",
    "    df_imputed = pd.DataFrame(imputed_array, columns=df_user.columns)\n",
    "\n",
    "    # 5. Decode categorical columns\n",
    "    for col in categorical_cols:\n",
    "        df_imputed[col] = df_imputed[col].round().astype(int)\n",
    "        valid_classes = label_encoders[col].classes_\n",
    "        df_imputed[col] = df_imputed[col].map(\n",
    "            lambda x: valid_classes[x] if x < len(valid_classes) else \"Unknown\"\n",
    "        )\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "# Example usage\n",
    "user_json = '''\n",
    "{\n",
    "  \"Process Stage\": \"Use\",\n",
    "  \"Technology\": \"Advanced\",\n",
    "  \"Location\": \"Europe\",\n",
    "  \"Raw Material Quantity (kg or unit)\": null,\n",
    "  \"Energy Input Quantity (MJ)\": null,\n",
    "  \"Transport Distance (km)\": 500,\n",
    "  \"Emissions to Air CO2 (kg)\": null\n",
    "}\n",
    "'''\n",
    "\n",
    "final_df = autofill_lca_data(user_json)\n",
    "print(\"Final Autofilled DataFrame:\")\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05009323-92ec-45e4-8b13-8b9f26791613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
